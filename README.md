# Data Platform Demo

A complete, self-contained demo of a modern lakehouse architecture using Apache Iceberg, Polaris, Trino, Kyuubi, and MinIO.

## ğŸš€ Quick Start (2 minutes)

```bash
# 1. Start all services
docker compose up -d

# 2. Extract Polaris credentials
bash scripts/get_polaris_token.sh

# 3. Verify everything works
source .polaris-env
curl -H "Authorization: Bearer $ACCESS_TOKEN" \
  http://localhost:8181/api/catalog/v1/config | jq .
```

## ğŸ“š Documentation

Start here based on your needs:

| Document | Purpose | Time |
|----------|---------|------|
| **[QUICKSTART.md](docs/QUICKSTART.md)** | Common tasks & commands | 5 min |
| **[TUTORIAL.md](docs/TUTORIAL.md)** | Complete step-by-step guide | 30 min |
| **[SETUP_NOTES.md](docs/SETUP_NOTES.md)** | Configuration details & fixes | 15 min |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Your Laptop                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Trino (SQL)          Kyuubi (Spark SQL)            â”‚
â”‚  localhost:8080       localhost:10009               â”‚
â”‚         â”‚                     â”‚                      â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                    â–¼                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚  Polaris REST Catalogâ”‚ (H2 in-memory)    â”‚
â”‚         â”‚  localhost:8181      â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                    â–¼                                â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚         â”‚  MinIO S3-compatible â”‚                    â”‚
â”‚         â”‚  localhost:9000      â”‚                    â”‚
â”‚         â”‚  console:9001        â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Folder Structure

```
demo-data-platform-query/
â”œâ”€â”€ docker-compose.yml          # Services definition
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ .gitignore                  # Git exclusions
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ QUICKSTART.md          # Fast reference
â”‚   â”œâ”€â”€ TUTORIAL.md            # Complete guide
â”‚   â”œâ”€â”€ SETUP_NOTES.md         # Configuration details
â”‚   â””â”€â”€ UPDATES_SUMMARY.md     # What was fixed
â”‚
â”œâ”€â”€ scripts/                    # Helper scripts
â”‚   â”œâ”€â”€ get_polaris_token.sh   # Extract credentials
â”‚   â””â”€â”€ pyspark_demo.py        # Spark example
â”‚
â”œâ”€â”€ config/                     # Service configurations
â”‚   â”œâ”€â”€ trino/etc/             # Trino config
â”‚   â””â”€â”€ kyuubi/                # Kyuubi/Spark config
â”‚
â”œâ”€â”€ data/                       # Runtime data (git-ignored)
â”‚   â”œâ”€â”€ minio/                 # Object store data
â”‚   â””â”€â”€ (auto-created)
â”‚
â””â”€â”€ .polaris-env               # Generated credentials (git-ignored)
```

## ğŸ”§ Services & Ports

| Service | Port | Purpose |
|---------|------|---------|
| **MinIO** | 9000 | S3-compatible object store |
| **MinIO Console** | 9001 | Web UI (user: minioadmin) |
| **Polaris** | 8181 | Iceberg REST catalog API |
| **Trino** | 8080 | Interactive SQL engine |
| **Kyuubi** | 10009 | Spark SQL over HiveServer2 |

## âœ¨ Key Features

- **Iceberg Tables** - ACID transactions, time-travel queries, schema evolution
- **Polaris Catalog** - REST-based metadata management, namespace/table governance
- **Trino** - SQL engine for interactive queries
- **Kyuubi** - Spark SQL server for notebook/JDBC connections
- **MinIO** - S3-compatible object storage for data files
- **Audit & Lineage** - Full query history via Iceberg `$history` and `$snapshots`

## ğŸ¯ First Steps

### Step 1: Start the Stack
```bash
docker compose up -d
```
Wait ~30 seconds for services to be ready.

### Step 2: Get Credentials
```bash
bash scripts/get_polaris_token.sh
```
This extracts the auto-generated Polaris credentials and obtains an OAuth token.

### Step 3: Create a Warehouse Bucket
```bash
docker exec demo-data-platform-query-minio-1 /usr/bin/mc alias set local http://localhost:9000 minioadmin minioadmin
docker exec demo-data-platform-query-minio-1 /usr/bin/mc mb local/demo-warehouse
```

### Step 4: Create Your First Table
Follow the **[TUTORIAL.md](docs/TUTORIAL.md)** for detailed examples using Trino, Kyuubi, or PySpark.

## ğŸ” Verify Everything Works

```bash
# Check services are running
docker compose ps

# Extract and load credentials
bash scripts/get_polaris_token.sh
source .polaris-env

# Test Polaris API
curl -H "Authorization: Bearer $ACCESS_TOKEN" \
  http://localhost:8181/api/catalog/v1/config | jq .

# Test Trino
trino --server localhost:8080 --catalog iceberg --schema default \
  -c "SELECT 1"
```

## ğŸ“– Learning Path

1. **Understand the basics** (5 min)
   - Read this README
   - Check the architecture diagram

2. **Run the quick start** (5 min)
   - Run commands in "Quick Start" section above
   - Access web UIs

3. **Follow the tutorial** (30 min)
   - See [TUTORIAL.md](docs/TUTORIAL.md)
   - Create tables with Trino
   - Query with Kyuubi
   - Explore with PySpark

4. **Explore advanced features** (ongoing)
   - Query Iceberg `$history` for audit trails
   - Test time-travel queries
   - Set up notifications
   - Create custom workflows

## ğŸ› Troubleshooting

### Services won't start
```bash
# Check logs
docker compose logs polaris
docker compose logs trino

# Restart everything
docker compose down && docker compose up -d
```

### Can't extract credentials
```bash
# Wait longer and try again
sleep 30
bash scripts/get_polaris_token.sh
```

### Trino can't create tables
- See **Troubleshooting** section in [TUTORIAL.md](docs/TUTORIAL.md)
- Key points: warehouse bucket must exist, Polaris must be accessible

For more detailed help, see [TUTORIAL.md](docs/TUTORIAL.md#troubleshooting).

## ğŸ§¹ Cleanup

```bash
# Stop and remove containers
docker compose down -v
```

This removes volumes and data. Configurations stay in the repo.

## ğŸ“š Additional Resources

- **Apache Iceberg**: https://iceberg.apache.org
- **Polaris Catalog**: https://polaris.apache.org
- **Trino**: https://trino.io
- **Kyuubi**: https://kyuubi.apache.org
- **MinIO**: https://min.io

## ğŸ’¡ Tips

- Credentials are auto-generated fresh on each startup
- Extract them immediately after `docker compose up -d`
- Store `.polaris-env` locally but don't commit it (it's in .gitignore)
- All data is stored in `./data/` which is ignored by git
- Use `docker logs <container>` to debug any service

## ğŸ¤ Contributing

Found an issue or have a suggestion? Feel free to:
1. Check [SETUP_NOTES.md](docs/SETUP_NOTES.md) for context
2. Review [UPDATES_SUMMARY.md](docs/UPDATES_SUMMARY.md) for recent changes
3. File an issue or submit a PR

---

**Ready?** Start with `docker compose up -d` and run the credential script! ğŸš€
